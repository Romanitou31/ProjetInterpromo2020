{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Group 1 - Facebook<span class=\"tocSkip\"></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Environnement\" data-toc-modified-id=\"Environnement-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Environnement</a></span><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Data-Loading\" data-toc-modified-id=\"Data-Loading-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Loading</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Crawl\" data-toc-modified-id=\"Crawl-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Crawl</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-JSON-file\" data-toc-modified-id=\"Create-JSON-file-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create JSON file</a></span></li></ul></li><li><span><a href=\"#Descriptive-statistics-on-recovered-data\" data-toc-modified-id=\"Descriptive-statistics-on-recovered-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Descriptive statistics on recovered data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the sources we need to scrap was the Facebook website (several pages).This notebook contains the code to retrieve the data and also the Robot to retrieve the data once a week. We scrapped posts on specifics pages. They contain for each publication, one comment, the publication date and number of comment, share and likes.\n",
    "\n",
    "V0 : Soup scrap + click function\n",
    "\n",
    "V2 : Comment recuperation + try of click on (\"more comment\") (only the first post is possible)\n",
    "\n",
    "V4 : Recuperation of likes, comment and share number + description\n",
    "\n",
    "V5 : Code formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common import action_chains\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part contains all the functions we developped during the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicSoup(url, link_driver, n_loop):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            url : url page\n",
    "            link_driver : driver link\n",
    "            n_boucle : scroll time number\n",
    "       out : \n",
    "            bs(driver.page_source, 'html.parser') : driver of the new page\n",
    "            driver : driver\n",
    "    \"\"\"\n",
    "    driver = webdriver.PhantomJS(link_driver)\n",
    "    driver.set_window_size(1400,1000)\n",
    "    driver.get(url)\n",
    "    y = 0\n",
    "        \n",
    "    for _ in range(n_loop):\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(\"+str(y)+\",\"+str(y+2000)+\")\")\n",
    "        time.sleep(2)\n",
    "        y += 2000\n",
    "    return bs(driver.page_source, 'html.parser'), driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clickShow(driver):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            driver : driver\n",
    "\n",
    "    \"\"\"\n",
    "    driver.find_element_by_class_name(\"_3j0u\").click()\n",
    "    elements = driver.find_elements_by_class_name(\"_4ssp\")\n",
    "    action = action_chains.ActionChains(driver)\n",
    "    for el in elements:\n",
    "        time.sleep(2)\n",
    "        try:\n",
    "            action.move_to_element(el)\n",
    "            time.sleep(4)\n",
    "            action.click(el)\n",
    "            action.perform()\n",
    "        except:\n",
    "            print(\"err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            text : character string\n",
    "            dic : dictionary which contains the changes to be made\n",
    "       out : \n",
    "            text : text with all changes made \n",
    "    \"\"\"\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simplification(chain):\n",
    "    # transform M into 1000000,  and K into 1000\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            chain : character string in format \"ex : 300K\"    \n",
    "       out : \n",
    "            int(float(expression) * coef) : integer  \"ex 300 000\"          \n",
    "    \"\"\"\n",
    "    chain = chain.replace(',', '.')\n",
    "    if '.' in chain:\n",
    "        expression = (re.search(\"\\d+\\.\\d+\", chain)).group(0)\n",
    "    else:\n",
    "        expression = (re.search(\"\\d+\", chain)).group(0)\n",
    "    coef = 1\n",
    "    if 'K' in chain:\n",
    "        coef = 1000\n",
    "    if 'M' in chain:\n",
    "        coef = 1000000\n",
    "    return(int(float(expression) * coef))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recovTextBetweenTags(texts: str, separator: str):\n",
    "    \"\"\" Retrieving code between two tags\n",
    "    \n",
    "    Paramters:\n",
    "        texts = Part of soup\n",
    "        separator = Separator of soup\n",
    "    Outers:\n",
    "        description = Text wanted\n",
    "    \"\"\" \n",
    "    text_clean = []\n",
    "    lisI = []\n",
    "    lisS = []\n",
    "\n",
    "    for i in range(0, len(texts)):\n",
    "        if str(texts[i]) == \"<\":\n",
    "            lisI.append(i)\n",
    "        if texts[i] == '>':\n",
    "            lisS.append(i)\n",
    "\n",
    "    len_lis = len(lisI)\n",
    "    for h in range(0, len_lis):\n",
    "        if h < (len_lis-1):\n",
    "            text_clean.append(texts[lisS[h]:lisI[h+1]])\n",
    "\n",
    "    if separator != 'non':\n",
    "        description = str(text_clean).replace('>', '').replace(\n",
    "            ',', '').replace('\\'', '').replace('ï¼Œ', '')\n",
    "        description = description.split(separator)\n",
    "    else:\n",
    "        description = text_clean\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateJs(listURL):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            url1_page\n",
    "            dic \n",
    "       out : \n",
    "            bs(driver.page_source, 'html.parser') : driver of the new page\n",
    "            driver : driver\n",
    "    \"\"\"\n",
    "\n",
    "    name_col = ['Data_Source',\n",
    "                'Airline_Name',\n",
    "                'Airline_Type',\n",
    "                'Region_Operation',\n",
    "                'Aircraft_Type',\n",
    "                'Cabin_Class',\n",
    "                'Type_Of_Lounge',\n",
    "                'Type_Of_Traveller',\n",
    "                'Date_Visit',\n",
    "                'Date_Flown',\n",
    "                'Airport',\n",
    "                'Route',\n",
    "                'Category',\n",
    "                'Category_Detail',\n",
    "                'Cabin_Staff_Service',\n",
    "                'Lounge_Staff_Service',\n",
    "                'Bar_And_Beverages',\n",
    "                'Food_And_Beverages',\n",
    "                'Ground_Service',\n",
    "                'Catering',\n",
    "                'Cleanliness',\n",
    "                'Lounge_Comfort',\n",
    "                'Aisle_Space',\n",
    "                'Wifi_And_Connectivity',\n",
    "                'Inflight_Entertainment',\n",
    "                'Viewing_Tv_Screen',\n",
    "                'Power_Supply',\n",
    "                'Seat',\n",
    "                'Seat_type',\n",
    "                'Seat_Comfort',\n",
    "                'Seat_Legroom',\n",
    "                'Seat_Storage',\n",
    "                'Seat_Width',\n",
    "                'Seat_Recline',\n",
    "                'Washrooms',\n",
    "                'Value_For_Money',\n",
    "                'Overall_Customer_Rating',\n",
    "                'Overall_Service_Rating',\n",
    "                'Overall_Airline_Rating',\n",
    "                'Recommended',\n",
    "                'Date_Review',\n",
    "                'Review',\n",
    "                'Departure_city',\n",
    "                'Arrival_city',\n",
    "                'Nb_bus_taken',\n",
    "                'Nb_train_taken',\n",
    "                'Nb_car_taken',\n",
    "                'Nb_plane_taken',\n",
    "                'Duration',\n",
    "                'Price_min',\n",
    "                'Price_max',\n",
    "                'Title',\n",
    "                'Author',\n",
    "                'Description',\n",
    "                'Date_publication',\n",
    "                'View_Count',\n",
    "                'Likes',\n",
    "                'Dislikes',\n",
    "                'Nb_subscribers',\n",
    "                'Nb_comments',\n",
    "                'Nb_sharing',\n",
    "                'Hashtags',\n",
    "                'Awards',\n",
    "                'Registration',\n",
    "                'Location',\n",
    "                'Contributions_Pers',\n",
    "                'Nb_pertinent_comments_Pers',\n",
    "                'Queuing_Times',\n",
    "                'Terminal_Seating',\n",
    "                'Terminal_Signs',\n",
    "                'Airport_Shopping',\n",
    "                'Experience_At_Airport']\n",
    "\n",
    "    dataAirline = pd.DataFrame(columns=name_col)\n",
    "\n",
    "    lien_driver = \"../Driver/phantomjs\"\n",
    "\n",
    "    dic2 = {'.': '', 'avril': '04', 'janvier': '01',\n",
    "            'mars': '03', 'mai': '05', 'juin': '06', 'fÃ©vrier': '02', 'juillet': '07', 'dÃ©cembre': '12',\n",
    "\n",
    "            'aoÃ»t': '08', 'septembre': '09', 'aoÃƒÂ»t': '08', 'dÃƒÂ©c': '12', 'novembre': '11'}\n",
    "\n",
    "    for ind, url in enumerate(listURL):\n",
    "        ur = url + 'posts/?ref=page_internal'\n",
    "        soup, driver = dynamicSoup(ur, lien_driver, 4)\n",
    "\n",
    "        # get likes\n",
    "        nb_like2 = []\n",
    "        desc = []\n",
    "        share2 = []\n",
    "        date2 = []\n",
    "        nb_com2 = []\n",
    "        comment1 = []\n",
    "        com2 = []\n",
    "        source = []\n",
    "        \n",
    "        for span in soup.findAll('div', attrs={'class': '_5pcr userContentWrapper'}):\n",
    "\n",
    "            nb_like = span.find('span', attrs={'class': '_81hb'})\n",
    "\n",
    "            if nb_like == None:\n",
    "                nb_like2.append(' ')\n",
    "            else:\n",
    "                nb_like2.append(\n",
    "                    int(str((str(Simplification(str(nb_like).replace('\\xa0', '').replace('>', '')))))))\n",
    "\n",
    "            description = span.find(\n",
    "                'div', attrs={'class': '_5pbx userContent _3576'})\n",
    "            if description == None:\n",
    "                desc.append(' ')\n",
    "                source.append('Facebook')\n",
    "            else:\n",
    "                desc.append(translate(str(recovTextBetweenTags(str(description), 'non')).replace(\n",
    "                    '\\'>\\',', '').replace('>', '')))\n",
    "                source.append('Facebook')\n",
    "\n",
    "            date1 = span.find(\n",
    "                'span', attrs={'class': 'timestampContent', 'id': re.compile(r'js_')})\n",
    "            if date1 == None:\n",
    "                date2.append(' ')\n",
    "            else:\n",
    "                date2.append(recovTextBetweenTags(str(date1), 'non'))\n",
    "\n",
    "            share1 = span.find('a', attrs={'class': '_3rwx _42ft'})\n",
    "            if share1 == None:\n",
    "                share2.append(' ')\n",
    "            else:\n",
    "                share2.append(recovTextBetweenTags(str(share1), 'non'))\n",
    "\n",
    "            nb_com = soup.find('a', attrs={'class': '_3hg- _42ft'})\n",
    "            if nb_com == None:\n",
    "                nb_com2.append(' ')\n",
    "            else:\n",
    "                nb_com2.append(recovTextBetweenTags(str(nb_com), 'non'))\n",
    "\n",
    "            com = span.find('span', attrs={'class': '_3l3x'})\n",
    "            if com == None:\n",
    "                com2.append(' ')\n",
    "            else:\n",
    "                com2.append(translate(str(recovTextBetweenTags(str(com), 'non')).replace(\n",
    "                    '>,', '').replace('>', '').replace('\\'\\', ', '')))\n",
    "\n",
    "        for i in range(0, len(date2)):\n",
    "            if('h' in (date2[i])):\n",
    "                date2[i] = str(date.today())\n",
    "            else:\n",
    "                date2[i] = replace_all(str(date2[i]), dic2)\n",
    "                if (re.search(\"^[0-9]*\\s[0-9]*,\", str(date2[i]))) != None:\n",
    "                    date2[i] = date2[i].split(\",\")[0]+' 2020'\n",
    "                    date2[i] = str(datetime.strptime(re.search(\n",
    "                        \"[0-9]* [0-9]* [0-9]*\", date2[i]).text.group(0), '%d %m %Y')).split(\" \")[0]\n",
    "        # get share\n",
    "        for i in range(0, len(share2)):\n",
    "            if share2[i] != ' ':\n",
    "                share2[i] = int(Simplification(str(share2[i]).replace(\n",
    "                    \"partages\", \"\").replace(\"\\xa0\", \"\").replace(\" \", \"\").replace(\">\", \"\")))\n",
    "\n",
    "        # get nb_com\n",
    "        for i in range(0, len(nb_com2)):\n",
    "            nb_com2[i] = Simplification(\n",
    "                str(nb_com2[i]).replace(\" commentaires\", \"\"))\n",
    "\n",
    "        # get comments\n",
    "        comments = driver.find_elements_by_xpath(\n",
    "            \"//div [@data-testid='UFI2Comment/body']\")\n",
    "        for i in range(0, len(comments)):\n",
    "            comment1.append(comments[i].text)\n",
    "        \n",
    "        df_template = pd.DataFrame({'Data_Source': source, 'Likes': nb_like2, 'Description': desc, 'Date_publication': date2,\n",
    "                                    'Nb_sharing': share2, 'Nb_comments': nb_com2, 'Review': com2})\n",
    "        dataAirline = pd.concat([dataAirline, df_template])\n",
    "\n",
    "        print('page numÃ©ro ', ind, ' fini')\n",
    "\n",
    "    return(dataAirline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the facebook pages to be scrapped in the pagesFb file, then scrape them one by one.\n",
    "\n",
    "def Create_List_URL(chain):\n",
    "    with open(chain, \"r\") as f :\n",
    "    \n",
    "        fb_pages = f.read()\n",
    "        files = fb_pages.split(\"\\n\")\n",
    "    return(files)\n",
    "\n",
    "def addJSON(file: str, df, creat: bool):\n",
    "    \"\"\"\n",
    "    Add of dataFrame in an existant JSON\n",
    "    Parameters:\n",
    "        file = path of JSON\n",
    "        df = dataFrame of news datas\n",
    "    Outers:\n",
    "        creat = description of fly\n",
    "    \"\"\"\n",
    "    \n",
    "    if creat is False :\n",
    "        with open(file) as train_file:\n",
    "            dict_train = json.load(train_file)\n",
    "        data = pd.read_json(dict_train, orient=\"records\")\n",
    "        df = pd.concat([data, df])\n",
    "    \n",
    "    js = df.to_json(orient='records').replace(\n",
    "        \"[\\\\\\\"[\", '').replace(\"]\\\\\\\"]\", '')\n",
    "    \n",
    "    with open(file, 'w', encoding='utf8') as outfile:\n",
    "        json.dump(js, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate (texte: str) : \n",
    "    \"\"\"\n",
    "    Paramters:\n",
    "        texte = Text to be translated\n",
    "    Outers:\n",
    "        new = Text translated\n",
    "    \"\"\"\n",
    "    try :\n",
    "        new = str(TextBlob(texte).translate(to='en'))\n",
    "        return new\n",
    "    except :\n",
    "        return texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:181: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page numÃ©ro  0  fini\n",
      "page numÃ©ro  1  fini\n",
      "page numÃ©ro  2  fini\n",
      "page numÃ©ro  3  fini\n",
      "page numÃ©ro  4  fini\n",
      "page numÃ©ro  5  fini\n",
      "page numÃ©ro  6  fini\n",
      "page numÃ©ro  7  fini\n",
      "page numÃ©ro  8  fini\n",
      "page numÃ©ro  9  fini\n",
      "page numÃ©ro  10  fini\n",
      "page numÃ©ro  11  fini\n",
      "page numÃ©ro  12  fini\n",
      "page numÃ©ro  13  fini\n",
      "page numÃ©ro  14  fini\n",
      "page numÃ©ro  15  fini\n",
      "page numÃ©ro  16  fini\n",
      "page numÃ©ro  17  fini\n",
      "page numÃ©ro  18  fini\n",
      "page numÃ©ro  19  fini\n",
      "page numÃ©ro  20  fini\n",
      "page numÃ©ro  21  fini\n",
      "page numÃ©ro  22  fini\n",
      "page numÃ©ro  23  fini\n",
      "page numÃ©ro  24  fini\n",
      "page numÃ©ro  25  fini\n",
      "page numÃ©ro  26  fini\n",
      "page numÃ©ro  27  fini\n",
      "page numÃ©ro  28  fini\n",
      "page numÃ©ro  29  fini\n",
      "page numÃ©ro  30  fini\n",
      "page numÃ©ro  31  fini\n",
      "page numÃ©ro  32  fini\n",
      "page numÃ©ro  33  fini\n",
      "page numÃ©ro  34  fini\n",
      "page numÃ©ro  35  fini\n",
      "page numÃ©ro  36  fini\n",
      "page numÃ©ro  37  fini\n",
      "page numÃ©ro  38  fini\n",
      "page numÃ©ro  39  fini\n"
     ]
    }
   ],
   "source": [
    "f = Create_List_URL(\"../pagesFb\")\n",
    "addJSON('../Results_json/data_Facebook.json',CreateJs(f),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics on recovered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Results_json/data_Facebook.json') as train_file:\n",
    "    dict_train = json.load(train_file)\n",
    "data = pd.read_json(dict_train, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aircraft_Type</th>\n",
       "      <th>Airline_Name</th>\n",
       "      <th>Airline_Type</th>\n",
       "      <th>Airport</th>\n",
       "      <th>Airport_Shopping</th>\n",
       "      <th>Aisle_Space</th>\n",
       "      <th>Arrival_city</th>\n",
       "      <th>Author</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Bar_And_Beverages</th>\n",
       "      <th>...</th>\n",
       "      <th>Terminal_Seating</th>\n",
       "      <th>Terminal_Signs</th>\n",
       "      <th>Title</th>\n",
       "      <th>Type_Of_Lounge</th>\n",
       "      <th>Type_Of_Traveller</th>\n",
       "      <th>Value_For_Money</th>\n",
       "      <th>View_Count</th>\n",
       "      <th>Viewing_Tv_Screen</th>\n",
       "      <th>Washrooms</th>\n",
       "      <th>Wifi_And_Connectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aircraft_Type  Airline_Name  Airline_Type  Airport  Airport_Shopping  \\\n",
       "0              NaN           NaN           NaN      NaN               NaN   \n",
       "1              NaN           NaN           NaN      NaN               NaN   \n",
       "2              NaN           NaN           NaN      NaN               NaN   \n",
       "3              NaN           NaN           NaN      NaN               NaN   \n",
       "4              NaN           NaN           NaN      NaN               NaN   \n",
       "..             ...           ...           ...      ...               ...   \n",
       "390            NaN           NaN           NaN      NaN               NaN   \n",
       "391            NaN           NaN           NaN      NaN               NaN   \n",
       "392            NaN           NaN           NaN      NaN               NaN   \n",
       "393            NaN           NaN           NaN      NaN               NaN   \n",
       "394            NaN           NaN           NaN      NaN               NaN   \n",
       "\n",
       "     Aisle_Space  Arrival_city  Author  Awards  Bar_And_Beverages  ...  \\\n",
       "0            NaN           NaN     NaN     NaN                NaN  ...   \n",
       "1            NaN           NaN     NaN     NaN                NaN  ...   \n",
       "2            NaN           NaN     NaN     NaN                NaN  ...   \n",
       "3            NaN           NaN     NaN     NaN                NaN  ...   \n",
       "4            NaN           NaN     NaN     NaN                NaN  ...   \n",
       "..           ...           ...     ...     ...                ...  ...   \n",
       "390          NaN           NaN     NaN     NaN                NaN  ...   \n",
       "391          NaN           NaN     NaN     NaN                NaN  ...   \n",
       "392          NaN           NaN     NaN     NaN                NaN  ...   \n",
       "393          NaN           NaN     NaN     NaN                NaN  ...   \n",
       "394          NaN           NaN     NaN     NaN                NaN  ...   \n",
       "\n",
       "     Terminal_Seating  Terminal_Signs  Title  Type_Of_Lounge  \\\n",
       "0                 NaN             NaN    NaN             NaN   \n",
       "1                 NaN             NaN    NaN             NaN   \n",
       "2                 NaN             NaN    NaN             NaN   \n",
       "3                 NaN             NaN    NaN             NaN   \n",
       "4                 NaN             NaN    NaN             NaN   \n",
       "..                ...             ...    ...             ...   \n",
       "390               NaN             NaN    NaN             NaN   \n",
       "391               NaN             NaN    NaN             NaN   \n",
       "392               NaN             NaN    NaN             NaN   \n",
       "393               NaN             NaN    NaN             NaN   \n",
       "394               NaN             NaN    NaN             NaN   \n",
       "\n",
       "     Type_Of_Traveller  Value_For_Money  View_Count Viewing_Tv_Screen  \\\n",
       "0                  NaN              NaN         NaN               NaN   \n",
       "1                  NaN              NaN         NaN               NaN   \n",
       "2                  NaN              NaN         NaN               NaN   \n",
       "3                  NaN              NaN         NaN               NaN   \n",
       "4                  NaN              NaN         NaN               NaN   \n",
       "..                 ...              ...         ...               ...   \n",
       "390                NaN              NaN         NaN               NaN   \n",
       "391                NaN              NaN         NaN               NaN   \n",
       "392                NaN              NaN         NaN               NaN   \n",
       "393                NaN              NaN         NaN               NaN   \n",
       "394                NaN              NaN         NaN               NaN   \n",
       "\n",
       "     Washrooms  Wifi_And_Connectivity  \n",
       "0          NaN                    NaN  \n",
       "1          NaN                    NaN  \n",
       "2          NaN                    NaN  \n",
       "3          NaN                    NaN  \n",
       "4          NaN                    NaN  \n",
       "..         ...                    ...  \n",
       "390        NaN                    NaN  \n",
       "391        NaN                    NaN  \n",
       "392        NaN                    NaN  \n",
       "393        NaN                    NaN  \n",
       "394        NaN                    NaN  \n",
       "\n",
       "[395 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nb_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>30.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>50.895053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>184.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Nb_comments\n",
       "count   395.000000\n",
       "mean     30.493671\n",
       "std      50.895053\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       5.000000\n",
       "75%      34.000000\n",
       "max     184.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Nb_comments']].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
