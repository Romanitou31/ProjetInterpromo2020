{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created on 09/01/2020\n",
    "# Group1\n",
    "# @authors: benjamin anton\n",
    "\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta,date\n",
    "import time\n",
    "import requests\n",
    "from urllib.request import Request, urlopen\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate (texte) : \n",
    "    try :\n",
    "        new = str(TextBlob(texte).translate(to='en'))\n",
    "        return new\n",
    "    except :\n",
    "        return texte\n",
    "    \n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideos(soup, limitDate=None):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            soup : soup for the request \n",
    "            limitDate : date on which we will filter video\n",
    "       out : \n",
    "            list_Videos : search equation videos list        \n",
    "    \"\"\"\n",
    "    videos = soup.findAll('a', attrs={'class': 'yt-uix-tile-link'})\n",
    "    dates = soup.findAll('ul', attrs={'class': 'yt-lockup-meta-info'})\n",
    "    \n",
    "    list_Videos = []\n",
    "    for i in range(len(videos)):\n",
    "        date = DateCalculation(str(dates[i]).split(\n",
    "            \"</li><li>\")[0].split(\"<li>\")[-1])\n",
    "        if limitDate is None:\n",
    "            list_Videos.append('https://www.youtube.com'+videos[i]['href'])\n",
    "        elif date > limitDate:\n",
    "            list_Videos.append('https://www.youtube.com'+videos[i]['href'])\n",
    "            \n",
    "    return list_Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create equation research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_Companies = [\n",
    "    \"American Airlines\",\n",
    "    \"Air Canada\",\n",
    "    \"Air France\",\n",
    "    \"Air Algerie\",\n",
    "    \"Air India\",\n",
    "    \"Aerolineas Argentinas\",\n",
    "    \"Royal Air Maroc\",\n",
    "    \"Finnair\",\n",
    "    \"Alitalia \",\n",
    "    \" Nouvelair\",\n",
    "    \"Air China\",\n",
    "    \"Cathay Pacific\",\n",
    "    \"Delta Airlines\",\n",
    "    \"Aer Lingus\",\n",
    "    \"Emirates\",\n",
    "    \"Ethiopian Airlines\",\n",
    "    \"Icelandair\",\n",
    "    \"Hawaiian Airlines\",\n",
    "    \"Iberia\",\n",
    "    \"Meridiana\",\n",
    "    \"Japan Airlines\",\n",
    "    \"KLM\",\n",
    "    \"Air Malta\",\n",
    "    \"Lan Airlines\",\n",
    "    \"Luxair\",\n",
    "    \"LIAT\",\n",
    "    \"LOT Polish Airlines\",\n",
    "    \"Air Madagascar\",\n",
    "    \"Air Mauritius\",\n",
    "    \"Austrian Airlines\",\n",
    "    \"Qatar Airways\",\n",
    "    \"South African Airways\",\n",
    "    \"SAS Scandinavian Airlines\",\n",
    "    \"Brussels Airlines\",\n",
    "    \"Singapore Airlines\",\n",
    "    \"Corsair\",\n",
    "    \"Aeroflot\",\n",
    "    \"Thai Airways\",\n",
    "    \"Turkish Airlines\",\n",
    "    \"TAP Portugal\",\n",
    "    \"Air Transat\",\n",
    "    \"Tunisair\",\n",
    "    \"Air Caraibes\",\n",
    "    \"United Airlines\",\n",
    "    \"Air Austral\",\n",
    "    \"Air Europa\",\n",
    "    \"Easyjet\",\n",
    "    \"Vietnam Airlines\",\n",
    "    \"Virgin Atlantic\",\n",
    "    \"Air Corsica\",\n",
    "    \"Condor\",\n",
    "    \"Flybe\",\n",
    "    \"Aegean Airlines\",\n",
    "    \"Air Tahiti Nui\",\n",
    "    \"Aigle Azur\",\n",
    "    \"HOP!\",\n",
    "    \"Jet Airways\",\n",
    "    \"Etihad Airways\",\n",
    "    \"Etihad Airways\",\n",
    "    \"Oman Air\",\n",
    "    \"XL Airways\",\n",
    "    \"Ryanair LTD\",\n",
    "    \"Vueling \",\n",
    "    \"Norwegian\",\n",
    "    \"Transavia France\",\n",
    "    \"Germanwings\",\n",
    "    \"TUI Fly Belgium\",\n",
    "    \"Air Arabia\",\n",
    "    \"WOW air\",\n",
    "    \"Wizz Air\",\n",
    "    \"Air Asia\",\n",
    "    \"Volotea\",\n",
    "    \"southwest airlines\"\n",
    "]\n",
    "Airline_Companies = [compagnies.replace(\n",
    "    ' ', '+') for compagnies in Airline_Companies]\n",
    "\n",
    "\n",
    "Boeing_Models = [\n",
    "    \"Boeing 717\",\n",
    "    \"Boeing 727\",\n",
    "    \"Boeing 737-200\",\n",
    "    \"Boeing 737-300\",\n",
    "    \"Boeing 737-400\",\n",
    "    \"Boeing 737-500\",\n",
    "    \"Boeing 737-600\",\n",
    "    \"Boeing 737-700\",\n",
    "    \"Boeing 737-700ER\",\n",
    "    \"Boeing 737-800\",\n",
    "    \"Boeing 737-900\",\n",
    "    \"Boeing 737-900ER\",\n",
    "    \"Boeing 737 MAX 7\",\n",
    "    \"Boeing 737 MAX 8\",\n",
    "    \"Boeing 737 MAX 9\",\n",
    "    \"Boeing 737 MAX 10\",\n",
    "    \"Boeing 747-200\",\n",
    "    \"Boeing 747-400\",\n",
    "    \"Boeing 757-200\",\n",
    "    \"Boeing 757-300\",\n",
    "    \"Boeing 767-200\",\n",
    "    \"Boeing 767-300\",\n",
    "    \"Boeing 767-300ER\",\n",
    "    \"Boeing 767-400ER\",\n",
    "    \"Boeing 777 Triple Seven\",\n",
    "    \"Boeing 787 DreamLiner\"\n",
    "]\n",
    "Boeing_Models = [models.replace(' ', '+') for models in Boeing_Models]\n",
    "\n",
    "\n",
    "Airbus_Models = [\n",
    "    \"A300\",\n",
    "    \"A300-600ST\",\n",
    "    \"A318\",\n",
    "    \"A319\",\n",
    "    \"A320-100\",\n",
    "    \"A320-200\",\n",
    "    \"A320neo\",\n",
    "    \"A321-100\",\n",
    "    \"A321-200\",\n",
    "    \"A330-200\",\n",
    "    \"A330-300\",\n",
    "    \"A330-200F\",\n",
    "    \"A330-500\",\n",
    "    \"A340-200\",\n",
    "    \"A340-300\",\n",
    "    \"A340-500\",\n",
    "    \"A340-600\",\n",
    "    \"A350-900\",\n",
    "    \"A350-1000\",\n",
    "    \"A380-800\",\n",
    "    \"A220-300\"\n",
    "]\n",
    "\n",
    "key_words = [\n",
    "    \"trip\",\n",
    "    \"fly\",\n",
    "    \"plane\",\n",
    "    \"airplane\",\n",
    "    \"flight\"\n",
    "]\n",
    "\n",
    "\n",
    "equations = []\n",
    "for comp in Airline_Companies:\n",
    "    for mod in Airbus_Models:\n",
    "        equations.append(comp+\"+\"+mod)\n",
    "    for mod in Boeing_Models:\n",
    "        equations.append(comp+\"+\"+mod)\n",
    "\n",
    "# quibbling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChangeDate(chain):\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            chain : character string in format \"ex :il ya 300 ans\"    \n",
    "       out : \n",
    "            expression.group(0) : character string in format  \"ex 300 ans\"          \n",
    "    \"\"\"\n",
    "    expression = re.search(\"[0-9]*\\s[a-zA-Z]*$\", chain)\n",
    "    return(expression.group(0))\n",
    "\n",
    "\n",
    "def Simplification(chain):\n",
    "    # transform M into 1000000,  and K into 1000\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            chain : character string in format \"ex : 300K\"    \n",
    "       out : \n",
    "            int(float(expression) * coef) : integer  \"ex 300 000\"          \n",
    "    \"\"\"\n",
    "    chain = chain.replace(',', '.')\n",
    "    if '.' in chain:\n",
    "        expression = (re.search(\"\\d+\\.\\d+\", chain)).group(0)\n",
    "    else:\n",
    "        expression = (re.search(\"\\d+\", chain)).group(0)\n",
    "    coef = 1\n",
    "    if 'k' in chain:\n",
    "        coef = 1000\n",
    "    if 'M' in chain:\n",
    "        coef = 1000000\n",
    "    return(int(float(expression) * coef))\n",
    "\n",
    "\n",
    "def DateCalculation(chain):\n",
    "    # calculate the exact date of publication of the video\n",
    "    \"\"\"Documentation    \n",
    "       Parameters :\n",
    "            chain : character string in format \"ex : il ya 300 ans\"    \n",
    "       out : \n",
    "            chain : date           \n",
    "    \"\"\"\n",
    "\n",
    "    chain = (chain).replace('il y a ', '')\n",
    "    day_nb=0\n",
    "    if 'hier' in chain:\n",
    "        day_nb = 1\n",
    "    else:\n",
    "        day_nb = int((re.search(\"\\d+\", chain)).group(0))\n",
    "    if 'mois' in chain:\n",
    "        day_nb = day_nb * 30\n",
    "    if 'an' in chain:\n",
    "        day_nb = day_nb * 365\n",
    "    if 'semaine' in chain:\n",
    "        day_nb = day_nb * 7\n",
    "\n",
    "    now = date.today()\n",
    "    return str(now - timedelta(days=(day_nb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the url list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def URLlist(Research_Equations,limitDate):\n",
    "    # returns the list of videos of the search equation passed in parameter\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            Research_Equations : search equation we want to launch    \n",
    "       out : \n",
    "            list_Videos : search equation videos list        \n",
    "    \"\"\"\n",
    "    root_URL = \"https://www.youtube.com/results?search_query=\"\n",
    "    #ResearchEquations = \"airbus+A380\"\n",
    "\n",
    "    r = requests.get(root_URL + Research_Equations)\n",
    "    page = r.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    list_Videos = getVideos(soup,limitDate)\n",
    "    return list_Videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function that creates our filled Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCodeHTML(URL_list, fig):\n",
    "    \"\"\"Documentation    \n",
    "\n",
    "       Parameters:\n",
    "            URL_list : list of url   \n",
    "            fig : url index processed\n",
    "       out :  \n",
    "            BeautifulSoup(web_page, 'html.parser') : return html code of the url page      \n",
    "    \"\"\"\n",
    "    url = URL_list[fig]\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    web_page = urlopen(req).read()\n",
    "    return BeautifulSoup(web_page, 'html.parser')\n",
    "\n",
    "\n",
    "def CreateJs(comment, nb_com, soup, comment_date):\n",
    "    # create the json file with all the information on the page\n",
    "    \"\"\"Documentation    \n",
    "\n",
    "       Parameters:\n",
    "            comment : character string of the comment\n",
    "            nb_com : number of comment\n",
    "            comment_date : comment date\n",
    "\n",
    "    \"\"\"\n",
    "    name_col = ['Airline_Name',\n",
    "                'Airline_Type',\n",
    "                'Region_Operation',\n",
    "                'Aircraft_Type',\n",
    "                'Cabin_Class',\n",
    "                'Type_Of_Lounge',\n",
    "                'Type_Of_Traveller',\n",
    "                'Date_Visit',\n",
    "                'Date_Flown',\n",
    "                'Airport',\n",
    "                'Route',\n",
    "                'Category',\n",
    "                'Category_Detail',\n",
    "                'Cabin_Staff_Service',\n",
    "                'Lounge_Staff_Service',\n",
    "                'Bar_And_Beverages',\n",
    "                'Food_And_Beverages',\n",
    "                'Ground_Service',\n",
    "                'Catering', 'Cleanliness',\n",
    "                'Lounge_Comfort',\n",
    "                'Aisle_Space',\n",
    "                'Wifi_And_Connectivity',\n",
    "                'Inflight_Entertainment',\n",
    "                'Viewing_Tv_Screen',\n",
    "                'Power_Supply',\n",
    "                'Seat',\n",
    "                'Seat_type',\n",
    "                'Seat_Comfort',\n",
    "                'Seat_Legroom',\n",
    "                'Seat_Storage',\n",
    "                'Seat_Width',\n",
    "                'Seat_Recline',\n",
    "                'Washrooms',\n",
    "                'Value_For_Money',\n",
    "                'Overall_Customer_Rating',\n",
    "                'Overall_Service_Rating',\n",
    "                'Overall_Airline_Rating',\n",
    "                'Recommended',\n",
    "                'Departure_city',\n",
    "                'Arrival_city',\n",
    "                'Nb_bus_taken',\n",
    "                'Nb_train_taken',\n",
    "                'Nb_car_taken',\n",
    "                'Nb_plane_taken',\n",
    "                'Duration',\n",
    "                'Price_min',\n",
    "                'Price_max',\n",
    "                'Nb_sharing',\n",
    "                'Awards',\n",
    "                'Registration',\n",
    "                'Language']\n",
    "\n",
    "    soup = soup\n",
    "    video_details = {}\n",
    "\n",
    "# Fill data\n",
    "\n",
    "    video_details['Data_Source'] = 'Youtube'\n",
    "\n",
    "    for i in range(39):\n",
    "        video_details[name_col[i]] = ' '\n",
    "\n",
    "    video_details['Date_Review'] = DateCalculation(comment_date)\n",
    "    video_details['Review'] = translate(comment)\n",
    "\n",
    "    for i in range(39, 48):\n",
    "        video_details[name_col[i]] = ' '\n",
    "\n",
    "# get the title of the video\n",
    "    video_details['Title'] = soup.find(\n",
    "        'span', attrs={'class': 'watch-title'}).text.strip()\n",
    "\n",
    "# get the name of the chain\n",
    "    for script in soup.findAll('script', attrs={'type': 'application/ld+json'}):\n",
    "        channelDescription = json.loads(script.text.strip())\n",
    "        video_details['Author'] = channelDescription['itemListElement'][0]['item']['name']\n",
    "\n",
    "# get description\n",
    "    video_details['Description'] = soup.find(\n",
    "        'p', attrs={'id': \"eow-description\"}).text.strip()\n",
    "\n",
    "# get the date of publication\n",
    "    dic = {'.':'','avr':'apr','janv':'jan','mars':'mar','mai':'may','juin':'jun','févr':'feb','juil':'jul','déc':'dec','août':'aug','sept':'sep','aoÃ»t':'aug','dÃ©c':'dec'}\n",
    "    var_date_of_public = soup.find('strong',attrs={'class': \"watch-time-text\"}).text.strip().replace('.','')\n",
    "    var_date_of_public = replace_all(var_date_of_public,dic)\n",
    "    var_date_not_None = re.search(\"[0-9][0-9]* [a-zA-Z]* [0-9]*\", var_date_of_public)\n",
    "    if var_date_not_None == None :\n",
    "        video_details['Date_publication'] = ''\n",
    "    else :\n",
    "        video_details['Date_publication'] = str(datetime.strptime(var_date_not_None.group(0), '%d %b %Y')). replace('00:00:00', '')\n",
    "\n",
    "# get the number of views\n",
    "    video_details['View_Count'] = (soup.find(\n",
    "        'div', attrs={'class': 'watch-view-count'}).text.strip()).replace('vues', '')\n",
    "\n",
    "# get a likes button\n",
    "    for span in soup.findAll('', attrs={'class': \"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-like-button like-button-renderer-like-button-unclicked yt-uix-clickcard-target yt-uix-tooltip\"}):\n",
    "        video_details['Likes'] = span.find(\n",
    "            'span', attrs={'class': 'yt-uix-button-content'}).text.strip()\n",
    "\n",
    "# get a dislikes button\n",
    "    for button in soup.findAll('button', attrs={'class': \"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-dislike-button like-button-renderer-dislike-button-unclicked yt-uix-clickcard-target yt-uix-tooltip\"}):\n",
    "        video_details['Dislikes'] = button.find(\n",
    "            'span', attrs={'class': 'yt-uix-button-content'}).text.strip()\n",
    "\n",
    "# get subscriber number\n",
    "    if (soup.find('span', attrs={'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}) == None):\n",
    "        video_details[\"Nb_subscribers\"] = 0\n",
    "    else:\n",
    "        video_details[\"Nb_subscribers\"] = Simplification(soup.find('span', attrs={\n",
    "                                                         'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}).text.strip())\n",
    "\n",
    "    video_details['Nb_comments'] = (nb_com).replace('commentaires', '')\n",
    "\n",
    "    video_details[name_col[48]] = ' '\n",
    "# get hashtags\n",
    "    hashtags = []\n",
    "\n",
    "    for span in soup.findAll('span', attrs={'class': 'standalone-collection-badge-renderer-text'}):\n",
    "        for a in span.findAll('a', attrs={'class': 'yt-uix-sessionlink'}):\n",
    "            hashtags.append(a.text.strip())\n",
    "    video_details['hashtags'] = hashtags\n",
    "\n",
    "    for i in range(49, 51):\n",
    "        video_details[name_col[i]] = ' '\n",
    "\n",
    "    video_details['Language'] = 'unknown'\n",
    "\n",
    "    if re.search(\"([a-z]).*\", str(comment).lower()) : \n",
    "        try :\n",
    "            video_details['Language'] = detect(comment)\n",
    "        except :\n",
    "            video_details['Language'] = 'unknown'\n",
    "\n",
    "        \n",
    "    with open('data.json', 'a', encoding='utf8') as outfile:\n",
    "        json.dump(video_details, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def scroll(url, nb_scroll):\n",
    "    #scroll down in the page\n",
    "    \"\"\"Documentation    \n",
    "       Parameters:\n",
    "            url : page url \n",
    "            nb_scroll : number of times you scroll  \n",
    "       out : \n",
    "            BeautifulSoup(driver.page_source, 'html.parser') : the new page after scroll\n",
    "            \n",
    "\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    driver =  webdriver.PhantomJS('Phantomjs_windows/phantomjs')\n",
    "    driver.get(url)\n",
    "    Y = 0\n",
    "    for _ in range(nb_scroll):\n",
    "        time.sleep(4)\n",
    "        driver.execute_script(\"window.scrollTo(\"+str(Y)+\",\"+str(Y+800)+\")\")\n",
    "        Y += 1200\n",
    "\n",
    "    return BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Romain\\Anaconda31\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead\n",
      "  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vidéo numéro :  0  fini\n",
      "vidéo numéro :  1  fini\n",
      "vidéo numéro :  2  fini\n",
      "vidéo numéro :  3  fini\n",
      "vidéo numéro :  4  fini\n",
      "vidéo numéro :  5  fini\n",
      "vidéo numéro :  6  fini\n",
      "équation finie : American+Airlines+A300\n",
      "vidéo numéro :  0  fini\n",
      "vidéo numéro :  1  fini\n",
      "vidéo numéro :  2  fini\n",
      "vidéo numéro :  3  fini\n",
      "vidéo numéro :  4  fini\n",
      "vidéo numéro :  5  fini\n",
      "vidéo numéro :  6  fini\n",
      "équation finie : American+Airlines+A300-600ST\n",
      "vidéo numéro :  0  fini\n",
      "vidéo numéro :  1  fini\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda31\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mtimeout\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-787ef6058ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_Videos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mURL_unique\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_Videos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msoup1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_Videos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mURL_unique\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mSoupCréeJS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetCodeHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_Videos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURL_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# date comment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-9890380da409>\u001b[0m in \u001b[0;36mscroll\u001b[1;34m(url, nb_scroll)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--start-maximized\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhantomJS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Phantomjs_windows/phantomjs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\selenium\\webdriver\\phantomjs\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, executable_path, port, desired_capabilities, service_args, service_log_path)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                 \u001b[0mcommand_executor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommand_executor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mbytes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRemoteConnection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_alive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, remote_server_addr, keep_alive, resolve_ip)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"https\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0mip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mport\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcommon_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_connectable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[0mip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 LOGGER.info('Could not connect to port {} on host '\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\site-packages\\selenium\\webdriver\\common\\utils.py\u001b[0m in \u001b[0;36mis_connectable\u001b[1;34m(port, host)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0msocket_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0msocket_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda31\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    714\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a new json\n",
    "\n",
    "with open('data.json', 'w', encoding='utf8') as outfile:\n",
    "    json\n",
    "\n",
    "for Equation in equations:\n",
    "    list_Videos = URLlist(Equation,None)\n",
    "    # len(list_Videos)\n",
    "    if len(list_Videos) > 1 :\n",
    "        for URL_unique in range(min(len(list_Videos),7)):\n",
    "            soup1 = scroll(list_Videos[URL_unique], 4)\n",
    "            SoupCréeJS = GetCodeHTML(list_Videos, URL_unique)\n",
    "        # date comment\n",
    "            date1 = []\n",
    "            for span1 in soup1.findAll('span', attrs={'class': \"comment-renderer-time\"}):\n",
    "                a = (span1.find('a', attrs={'class': \"yt-uix-sessionlink spf-link\"}).text.strip())\n",
    "                date1.append(a)\n",
    "            date_Track = 0\n",
    "            for span in soup1.findAll('div', attrs={'class': 'comment-renderer-text-content'}):\n",
    "                if span.text.strip() != '':\n",
    "                    comment = span.text.strip()\n",
    "                    nb_com = re.search(\"[0-9][0-9]*\", (soup1.find('h2', \n",
    "                                                                 attrs={'class': 'comment-section-header-renderer'}).text.strip()).replace('\\xa0',' ').replace('\\u202f','')).group(0)\n",
    "                    CreateJs(comment, nb_com, SoupCréeJS, date1[date_Track])\n",
    "                    date_Track += 1\n",
    "            print('vidéo numéro : ', URL_unique, ' fini')\n",
    "        print('équation finie :', Equation)\n",
    "print('extraction complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'.':'','avr':'apr','janv':'jan','mars':'mar','mai':'may','juin':'jun','févr':'feb','juil':'jul','déc':'dec','août':'aug','sept':'sep','aoÃ»t':'aug','dÃ©c':'dec'}\n",
    "var_date_of_public = SoupCréeJS.find('strong',attrs={'class': \"watch-time-text\"}).text.strip().replace('.','')\n",
    "var_date_of_public = replace_all(var_date_of_public,dic)\n",
    "str(datetime.strptime(re.search(\"[0-9][0-9]* [a-zA-Z]* [0-9]*\", var_date_of_public).group(0), '%d %b %Y')). replace('00:00:00', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SoupCréeJS.find('span', attrs={'class': 'watch-title'}).text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
