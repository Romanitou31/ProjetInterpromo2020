import urllib.request
import urllib.parse
import urllib.error
import ssl
import json
import ast
import os
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup as bs
import requests

##############################################################################
### RECUPERATION DES URL DES VIDEOS ##########################################
##############################################################################
# A faire : trouver un moyen de récupérer + des 30 vidéos de bases (actualisation
# de la page)
racineURL = "https://www.youtube.com/results?search_query="
EquationRecherche = "airbus+A380"

r = requests.get(racineURL + EquationRecherche)
page = r.text
soup = bs(page,'html.parser')

videos = soup.findAll('a',attrs={'class':'yt-uix-tile-link'})

listVideos=[]   
for v in videos:
    URL = 'https://www.youtube.com' + v['href']
    listVideos.append(URL)   

##############################################################################
### RECUPERATION DES INFOS D'UNE VIDEO #######################################
##############################################################################
# A faire : Récupérer Description / Commentaires

url = input('Enter Youtube Video Url- ')
req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
webpage = urlopen(req).read()
dir(requests)

soup = bs(webpage, 'html.parser')
html = soup.prettify('utf-8')
video_details = {}

### Titre de la vidéo
video_details['Titre'] = soup.find('span',attrs={'class': 'watch-title'}).text.strip()

### Nom de la chaîne
for script in soup.findAll('script',attrs={'type': 'application/ld+json'}):
    channelDescription = json.loads(script.text.strip())
    video_details['Nom chaine'] = channelDescription['itemListElement'][0]['item']['name']

### Nombre de vues
video_details['Nombre de vues'] =soup.find('div',attrs={'class': 'watch-view-count'}).text.strip()

### Nombre d'abonnés
video_details["Nombre d'abonnés"] =soup.find('span',attrs={'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}).text.strip()

### Nombre de Likes
for span in soup.findAll('',attrs={'class':"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-like-button like-button-renderer-like-button-unclicked yt-uix-clickcard-target yt-uix-tooltip"}):
    video_details['LIKES']=span.find('span',attrs={'class':'yt-uix-button-content'}).text.strip()

### Nombre de Dislikes
for button in soup.findAll('button',attrs={'class':"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-dislike-button like-button-renderer-dislike-button-unclicked yt-uix-clickcard-target yt-uix-tooltip"}):
    video_details['DISLIKES']=button.find('span',attrs={'class':'yt-uix-button-content'}).text.strip()

### Liste des hashtags
hashtags = []
for span in soup.findAll('span',attrs={'class': 'standalone-collection-badge-renderer-text'}):
    for a in span.findAll('a',attrs={'class': 'yt-uix-sessionlink'}):
        hashtags.append(a.text.strip())
video_details['Référence'] = hashtags

### Description
video_details['Description'] = soup.find('p',attrs={'id': "eow-description"}).text.strip()
        
# A corriger


for script in soup.findAll('script'):
        test = json.loads(script.text.strip())
# FAUX        
com = []
for span in soup.findAll('a',attrs={'class': 'yt-formatted-string'}):
    print(span)
    for a in span.findAll('span',attrs={'class': 'style-scope ytd-comment-renderer'}):
        print('ok')
        com.append(a.text.strip())
video_details['Commentaires'] = com
for link in soup.findAll(id="content-text"):
    print(link.get_text())
 n
###########    
    
    
    
with open('output_file.html', 'wb') as file:
    file.write(html)

with open('data1.json', 'a', encoding='utf8') as outfile:
    json.dump(video_details, outfile, ensure_ascii=False,indent=4)

print ('Extraction finie')