{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "from langdetect import detect\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create equation research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3431\n"
     ]
    }
   ],
   "source": [
    "compagniesAeriennes=[\"American Airlines\",\"Air Canada\",\"Air France\",\"Air Algerie\",\"Air India\",\"Aerolineas Argentinas\",\"Royal Air Maroc\",\"Finnair\" ,\"Alitalia \",\" Nouvelair\",\"Air China\",\"Cathay Pacific\",\"Delta Airlines\",\"Aer Lingus\",\"Emirates\",\"Ethiopian Airlines\",\"Icelandair\",\"Hawaiian Airlines\",\"Iberia\",\"Meridiana\",\"Japan Airlines\",\"KLM\",\"Air Malta\",\"Lan Airlines\",\"Luxair\",\"LIAT\",\"LOT Polish Airlines\",\"Air Madagascar\",\"Air Mauritius\",\"Austrian Airlines\",\"Qatar Airways\",\"South African Airways\",\"SAS Scandinavian Airlines\",\"Brussels Airlines\",\"Singapore Airlines\",\"Corsair\",\"Aeroflot\",\"Thai Airways\",\"Turkish Airlines\",\"TAP Portugal\",\"Air Transat\",\"Tunisair\",\"Air Caraibes\",\"United Airlines\",\"Air Austral\",\"Air Europa\",\"Easyjet\",\"Vietnam Airlines\",\"Virgin Atlantic\",\"Air Corsica\",\"Condor\",\"Flybe\",\"Aegean Airlines\",\"Air Tahiti Nui\",\"Aigle Azur\",\"HOP!\",\"Jet Airways\",\"Etihad Airways\",\"Etihad Airways\",\"Oman Air\",\"XL Airways\",\"Ryanair LTD\",\"Vueling \",\"Norwegian\",\"Transavia France\",\"Germanwings\",\"TUI Fly Belgium\",\"Air Arabia\",\"WOW air\",\"Wizz Air\",\"Air Asia\",\"Volotea\",\"southwest airlines\"]\n",
    "compagniesAeriennes = [compagnies.replace(' ','+') for compagnies in compagniesAeriennes]\n",
    "\n",
    "modelesBoeing=[\"Boeing 717\",\"Boeing 727\",\"Boeing 737-200\",\"Boeing 737-300\",\"Boeing 737-400\",\"Boeing 737-500\",\"Boeing 737-600\",\"Boeing 737-700\",\"Boeing 737-700ER\",\"Boeing 737-800\",\"Boeing 737-900\",\"Boeing 737-900ER\",\"Boeing 737 MAX 7\",\"Boeing 737 MAX 8\",\"Boeing 737 MAX 9\",\"Boeing 737 MAX 10\",\"Boeing 747-200\",\"Boeing 747-400\",\"Boeing 757-200\",\"Boeing 757-300\",\"Boeing 767-200\",\"Boeing 767-300\",\"Boeing 767-300ER\",\"Boeing 767-400ER\",\"Boeing 777 Triple Seven\",\"Boeing 787 DreamLiner\"]\n",
    "modelesBoeing = [modele.replace(' ','+') for modele in modelesBoeing]\n",
    "\n",
    "modelesAirbus=[\"A300\",\"A300-600ST\",\"A318\",\"A319\",\"A320-100\",\"A320-200\",\"A320neo\",\"A321-100\",\"A321-200\",\"A330-200\",\"A330-300\",\"A330-200F\",\"A330-500\",\"A340-200\",\"A340-300\",\"A340-500\",\"A340-600\",\"A350-900\",\"A350-1000\",\"A380-800\",\"A220-300\"]\n",
    "motsCles=[\"trip\",\"fly\",\"plane\",\"airplane\",\"flight\"]\n",
    "\n",
    "\n",
    "equations=[]\n",
    "for comp in compagniesAeriennes:\n",
    "    for mod in modelesAirbus:\n",
    "        equations.append(comp+\"+\"+mod)\n",
    "    for mod in modelesBoeing:\n",
    "        equations.append(comp+\"+\"+mod)\n",
    "print(len(equations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fonction chipottage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifierDate(chaine):\n",
    "    expression=re.search(\"[0-9]*\\s[a-zA-Z]*$\" ,chaine)\n",
    "    return(expression.group(0))\n",
    "\n",
    "def Simplification(chaine):\n",
    "    chaine = chaine.replace(',','.')\n",
    "    if '.' in chaine :\n",
    "        expression=(re.search(\"\\d+\\.\\d+\" ,chaine)).group(0)\n",
    "    else : \n",
    "        expression=(re.search(\"\\d+\" ,chaine)).group(0)\n",
    "    facteur = 1\n",
    "    if 'k' in chaine : \n",
    "        facteur = 1000\n",
    "    if 'M' in chaine : \n",
    "        facteur = 1000000\n",
    "    return(int(float(expression) * facteur))\n",
    "\n",
    "\n",
    "def fctdate1(chaine):\n",
    "    chaine=(chaine).replace('il y a ','')\n",
    "    if 'hier' in chaine : \n",
    "        nb_jour = 1\n",
    "    else : \n",
    "        nb_jour = int((re.search(\"\\d+\" ,chaine)).group(0))\n",
    "    if 'mois' in chaine: \n",
    "        nb_jour = nb_jour * 30\n",
    "    if 'ans' in chaine : \n",
    "        nb_jour = nb_jour * 365\n",
    "    if 'semaine' in chaine :\n",
    "        nb_jour = nb_jour * 7\n",
    "        \n",
    "    now = date.today()\n",
    "    return str(now - timedelta(days = (nb_jour)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de la liste URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listeUR (EquationRecherche) :\n",
    "    racineURL = \"https://www.youtube.com/results?search_query=\"\n",
    "    #EquationRecherche = \"airbus+A380\"\n",
    "\n",
    "    r = requests.get(racineURL + EquationRecherche)\n",
    "    page = r.text\n",
    "    soup = bs(page,'html.parser')\n",
    "\n",
    "    videos = soup.findAll('a',attrs={'class':'yt-uix-tile-link'})\n",
    "    listVideos=[]\n",
    "    for v in videos:\n",
    "        URL = 'https://www.youtube.com' + v['href']\n",
    "        listVideos.append(URL)\n",
    "    return listVideos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction qui nous crée notre fichier Json remplie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCodeHTML(listeURL,chiffre):\n",
    "    url = listeURL[chiffre]\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    return BeautifulSoup(webpage, 'html.parser')\n",
    "    \n",
    "def CréeJs(commentaire,nb_com, soup,date_commentaire) :\n",
    "    nom_col = ['Airline_Name','Airline_Type','Region_Operation','Aircraft_Type','Cabin_Class','Type_Of_Lounge',\n",
    "               'Type_Of_Traveller','Date_Visit','Date_Flown','Airport','Route','Category','Category_Detail',\n",
    "               'Cabin_Staff_Service','Lounge_Staff_Service','Bar_And_Beverages','Food_And_Beverages','Ground_Service','Catering','Cleanliness',\n",
    "              'Lounge_Comfort','Aisle_Space','Wifi_And_Connectivity','Inflight_Entertainment','Viewing_Tv_Screen','Power_Supply',\n",
    "              'Seat','Seat_type','Seat_Comfort','Seat_Legroom','Seat_Storage','Seat_Width','Seat_Recline','Washrooms',\n",
    "               'Value_For_Money','Overall_Customer_Rating','Overall_Service_Rating','Overall_Airline_Rating',\n",
    "              'Recommended','Departure_city','Arrival_city','Nb_bus_taken','Nb_train_taken',\n",
    "               'Nb_car_taken','Nb_plane_taken','Duration','Price_min','Price_max','Nb_sharing','Awards','Registration','Language']\n",
    "    \n",
    "    soup = soup \n",
    "    video_details = {}\n",
    "    \n",
    "#Fill data\n",
    "\n",
    "    video_details['Data_Source'] = 'Youtube'\n",
    "    \n",
    "    for i in range (39) : \n",
    "        video_details[nom_col[i]] = ' '\n",
    "    \n",
    "    video_details['Date_Review'] = fctdate1(date_commentaire)\n",
    "    video_details['Review'] = commentaire\n",
    "    \n",
    "    for i in range (39,48) :\n",
    "        video_details[nom_col[i]] = ' '\n",
    "        \n",
    "#sortir le titre de la vidéo\n",
    "    video_details['Title'] = soup.find('span',attrs={'class': 'watch-title'}).text.strip()\n",
    "\n",
    "#sortir le nom de la chaine\n",
    "    for script in soup.findAll('script',attrs={'type': 'application/ld+json'}):\n",
    "        channelDescription = json.loads(script.text.strip())\n",
    "        video_details['Author'] = channelDescription['itemListElement'][0]['item']['name']\n",
    "        \n",
    "#sortir description\n",
    "    video_details['Description'] = soup.find('p',attrs={'id': \"eow-description\"}).text.strip()\n",
    "    \n",
    "#sortir la date de publication \n",
    "    video_details['Date_publication'] = str(datetime.strptime(soup.find('strong',attrs={'class': \"watch-time-text\"}).text.strip().replace('Ajoutée le','').replace('.',''), '%d %b %Y')). replace('00:00:00','')\n",
    "#sortir le nombre de vue\n",
    "    video_details['View_Count'] = (soup.find('div',attrs={'class': 'watch-view-count'}).text.strip()).replace('vues','')\n",
    "\n",
    "#sortir un bouton likes\n",
    "    for span in soup.findAll('',attrs={'class':\"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-like-button like-button-renderer-like-button-unclicked yt-uix-clickcard-target yt-uix-tooltip\"}):\n",
    "        video_details['Likes']= span.find('span',attrs={'class':'yt-uix-button-content'}).text.strip()\n",
    "\n",
    "\n",
    "#sortir un bouton de dislikes \n",
    "    for button in soup.findAll('button',attrs={'class':\"yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-dislike-button like-button-renderer-dislike-button-unclicked yt-uix-clickcard-target yt-uix-tooltip\"}):\n",
    "        video_details['Dislikes']=button.find('span',attrs={'class':'yt-uix-button-content'}).text.strip()\n",
    "\n",
    "#sortir le nombre d'abonné\n",
    "    if (soup.find('span',attrs={'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}) == None):\n",
    "        video_details[\"Nb_subscribers\"] = 0\n",
    "    else :\n",
    "        video_details[\"Nb_subscribers\"] = Simplification(soup.find('span',attrs={'class': 'yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count'}).text.strip())\n",
    "        \n",
    "\n",
    "    video_details['Nb_comments'] = (nb_com).replace('commentaires','')\n",
    "    \n",
    "    video_details[nom_col[48]] = ' '\n",
    "#sortir hashtags\n",
    "    hashtags = []\n",
    "\n",
    "    for span in soup.findAll('span',attrs={'class': 'standalone-collection-badge-renderer-text'}):\n",
    "        for a in span.findAll('a',attrs={'class': 'yt-uix-sessionlink'}):\n",
    "            hashtags.append(a.text.strip())\n",
    "    video_details['hashtags'] = hashtags\n",
    "    \n",
    "    \n",
    "    for i in range (49,51):\n",
    "        video_details[nom_col[i]] = ' '\n",
    "    \n",
    "    #detect(str(commentaire[0]))\n",
    "    video_details['Language'] = 'unknown'\n",
    "    if re.search(\"([a-z]).*\", str(commentaire).lower()) :\n",
    "        video_details['Language'] = detect(str(commentaire))\n",
    "    \n",
    "\n",
    "    with open('data.json', 'a', encoding='utf8') as outfile:\n",
    "        json.dump(video_details, outfile, ensure_ascii=False,indent=4)\n",
    "\n",
    "        \n",
    "        \n",
    "def scroll (url,nb_scroll):\n",
    "    options = Options() \n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument('headless')\n",
    "    driver = webdriver.Chrome(\"/home/sid2019-13/Téléchargements/chromedriver\",options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    Y=0\n",
    "    for _ in range(nb_scroll):\n",
    "        time.sleep(4)\n",
    "        driver.execute_script(\"window.scrollTo(\"+str(Y)+\",\"+str(Y+800)+\")\")\n",
    "        Y+=800\n",
    "    return BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vidéo numéro :  0  fini\n",
      "équation fini\n",
      "extraction complete\n",
      "CPU times: user 3.97 s, sys: 229 ms, total: 4.2 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a new json\n",
    "\n",
    "with open('data.json', 'w', encoding='utf8') as outfile: json\n",
    "\n",
    "for Equation in equations[:1] :\n",
    "    listVideos = listeUR (Equation)\n",
    "    #for URLunique in range(len(listVideos)-27):\n",
    "    for URLunique in range(1):\n",
    "        soup1 = scroll(listVideos[URLunique],4)\n",
    "        SoupCréeJS = GetCodeHTML(listVideos,URLunique)\n",
    "\n",
    "    #date comment\n",
    "\n",
    "        date1 = []\n",
    "        for span1 in soup1.findAll('yt-formatted-string',attrs={'class':\"published-time-text above-comment style-scope ytd-comment-renderer\"}):\n",
    "            a = (span1.find('a',attrs={'class': 'yt-simple-endpoint style-scope yt-formatted-string'}).text.strip())\n",
    "            date1.append(a)  \n",
    "\n",
    "        suivi_date = 0\n",
    "        for span in soup1.findAll('yt-formatted-string',attrs={'class': 'style-scope ytd-comment-renderer'}):\n",
    "            if span.text.strip() != '':\n",
    "                commentaire = span.text.strip()\n",
    "                nb_com = soup1.find('yt-formatted-string',attrs={'class': 'count-text style-scope ytd-comments-header-renderer'}).text.strip()\n",
    "                CréeJs(commentaire,nb_com,SoupCréeJS,date1[suivi_date])\n",
    "                suivi_date += 1\n",
    "\n",
    "        print('vidéo numéro : ',URLunique, ' fini')\n",
    "    print('équation fini')\n",
    "print('extraction complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
