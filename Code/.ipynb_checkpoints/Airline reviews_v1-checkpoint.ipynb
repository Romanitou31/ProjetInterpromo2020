{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good = Date_Flown, Cleanliness, Food_And_Beverages, Wifi_And_Connectivity, Cabin_Staff_Service,Recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad = Queuing Times,Terminal Seating, Terminal Signs, Airport shopping,Experience At Airport,Type Of Traveller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupTexteEntreBalise(texte, separateur):\n",
    "    \n",
    "    texte2 = []\n",
    "    lisI = []\n",
    "    lisS = []\n",
    "    \n",
    "    for i in range(0,len(texte)):\n",
    "        if str(texte[i]) == \"<\":\n",
    "            lisI.append(i)\n",
    "        if texte[i] == '>':\n",
    "            lisS.append(i)   \n",
    "\n",
    "    taille = len(lisI)\n",
    "    for h in range(0,taille):\n",
    "        if h < (taille-1):\n",
    "            texte2.append(texte[lisS[h]:lisI[h+1]])\n",
    "    \n",
    "    if separateur != 'non':\n",
    "        description = str(texte2).replace('>','').replace(',','').replace('\\'','').replace('，','')\n",
    "        description = description.split(separateur)\n",
    "    else:\n",
    "        description = texte2\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corp(listURL):\n",
    "    \n",
    "    nom_col = ['Airline_Name',\n",
    "               'Airline_Type',\n",
    "               'Region_Operation','Aircraft_Type','Cabin_Class','Type_Of_Lounge',\n",
    "                   'Type_Of_Traveller','Date_Visit','Date_Flown','Airport','Route','Category','Category_Detail',\n",
    "                   'Cabin_Staff_Service','Lounge_Staff_Service','Bar_And_Beverages','Food_And_Beverages','Ground_Service','Catering','Cleanliness',\n",
    "                  'Lounge_Comfort','Aisle_Space','Wifi_And_Connectivity','Inflight_Entertainment','Viewing_Tv_Screen','Power_Supply',\n",
    "                  'Seat','Seat_type','Seat_Comfort','Seat_Legroom','Seat_Storage','Seat_Width','Seat_Recline','Washrooms',\n",
    "                   'Value_For_Money','Overall_Customer_Rating','Overall_Service_Rating','Overall_Airline_Rating',\n",
    "                  'Recommended','Departure_city','Arrival_city','Nb_bus_taken','Nb_train_taken',\n",
    "                   'Nb_car_taken','Nb_plane_taken','Duration','Price_min','Price_max','Nb_sharing','Awards','Registration','Language']\n",
    "    \n",
    "    dataAirline = pd.DataFrame(columns = nom_col)\n",
    "    \n",
    "    for URL in listURL:\n",
    "        r = requests.get(URL)\n",
    "        page = r.text\n",
    "        soup = bs(page,'html.parser')\n",
    "        Nb_com = notation(soup)[5]\n",
    "        \n",
    "        for j in range (1,int(Nb_com)//10+2):\n",
    "            r = requests.get(URL+'page/'+str(j)+'/')\n",
    "            page = r.text\n",
    "            soup = bs(page,'html.parser')\n",
    "            title = notation(soup)[1]\n",
    "            desc = notation(soup)[2]\n",
    "            note = UserNot(soup)\n",
    "\n",
    "            airport=[]\n",
    "            for i in range(0,len(desc)):\n",
    "                airport.append(URL[47:])\n",
    "\n",
    "            df = pd.DataFrame(data=[title, desc, note, airport])\n",
    "            df=df.transpose()\n",
    "\n",
    "            Title = df[0]\n",
    "            Review = df[1]\n",
    "            Date_Visit, Terminal_Cleanliness, Food_Beverages, Wifi_Connectivity, Airport_Staff, Recommended = dic_col(df[2])\n",
    "            Airport = df[3]\n",
    "            # o.columns = ['Title', 'Review', 'Date_Flown', 'Cleanliness', 'Food_And_Beverages', 'Wifi_And_Connectivity', 'Cabin_Staff_Service','Recommended', 'Airport']\n",
    "            o = pd.DataFrame({'Date_Flown': Date_Visit, 'Cleanliness': Terminal_Cleanliness, 'Food_And_Beverages': Food_Beverages,\n",
    "                              'Wifi_And_Connectivity' : Wifi_Connectivity, 'Cabin_Staff_Service': Airport_Staff,\n",
    "                             'Recommended':Recommended, 'Title': Title, 'Review': Review, 'Airport': Airport })\n",
    "\n",
    "            dataAirline = pd.concat([dataAirline, o])\n",
    "\n",
    "\n",
    "    return dataAirline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listURL=[]\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/singapore-changi-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/paris-cdg-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/new-york-jfk-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/london-city-airport/')\n",
    "#listURL.append('https://www.airlinequality.com/airport-reviews/berlin-schonefeld-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/rome-ciampino-airport/')\n",
    "dataAirline = corp(listURL)\n",
    "c = dataAirline.to_json(orient='records')\n",
    "with open('dataAirline.json', 'a', encoding='utf8') as outfile:\n",
    "        json.dump(c, outfile, ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_col(o):\n",
    "# Prend en paramètre la colonne du DF contenant le dictionnaire des notes\n",
    "    Date_Visit = []\n",
    "    Terminal_Cleanliness = [] \n",
    "    Food_Beverages = [] \n",
    "    Wifi_Connectivity = []\n",
    "    Airport_Staff = []\n",
    "    Recommended = []\n",
    "\n",
    "    for i in range(0,len(o)):\n",
    "        if 'Date Visit' in (o[i]).keys():\n",
    "            Date_Visit.append((o[i]['Date Visit']))\n",
    "        else:\n",
    "            Date_Visit.append(' ')\n",
    "\n",
    "        if ' Terminal Cleanliness' in (o[i]).keys():\n",
    "            Terminal_Cleanliness.append((o[i][' Terminal Cleanliness']))\n",
    "        else:\n",
    "            Terminal_Cleanliness.append(' ')\n",
    "\n",
    "        if ' Food Beverages' in (o[i]).keys():\n",
    "            Food_Beverages.append((o[i][' Food Beverages']))\n",
    "        else:\n",
    "            Food_Beverages.append(' ')\n",
    "\n",
    "        if ' Wifi Connectivity' in (o[i]).keys():\n",
    "            Wifi_Connectivity.append((o[i][' Wifi Connectivity']))\n",
    "        else:\n",
    "            Wifi_Connectivity.append(' ')\n",
    "\n",
    "        if ' Airport Staff' in (o[i]).keys():\n",
    "            Airport_Staff.append((o[i][' Airport Staff']))\n",
    "        else:\n",
    "            Airport_Staff.append(' ')\n",
    "\n",
    "        if ' Recommended' in (o[i]).keys():\n",
    "            Recommended.append((o[i][' Recommended']))\n",
    "        else:\n",
    "            Recommended.append(' ')\n",
    "    return  Date_Visit, Terminal_Cleanliness, Food_Beverages, Wifi_Connectivity, Airport_Staff, Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notation(soup):\n",
    "    note = []\n",
    "    title = []\n",
    "    desc = []\n",
    "    title_column = []\n",
    "    note2 = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':'review'}):\n",
    "        star_fill = span.findAll('span',attrs={'class':'star fill'})\n",
    "        star_fill2 = re.findall(r'[0-9]',str(star_fill))\n",
    "        if len(star_fill2)>0:\n",
    "            noteUser = []\n",
    "            taille = len(star_fill2)\n",
    "            for i in range(0,taille-1):\n",
    "                if star_fill2[i] >= star_fill2[i+1]:\n",
    "                    noteUser.append(star_fill2[i])\n",
    "            noteUser.append(star_fill2[taille-1])\n",
    "            note.append(noteUser)\n",
    "        textH = span.findAll('h2',attrs={'class':'text_header'})\n",
    "        textH = recupTexteEntreBalise(str(textH),'non')\n",
    "        title.append(textH[0][1:len(textH[0])])\n",
    "        content = span.findAll('div',attrs={'class':'text_content'})\n",
    "        desc.append(recupTexteEntreBalise(str(content),','))\n",
    "        rating_header = span.findAll('td',attrs={'class':\"review-rating-header\"})\n",
    "        rating_header = recupTexteEntreBalise(str(rating_header),',')\n",
    "        rating_header = rating_header[0][1:len(rating_header[0])-1]\n",
    "        title_column.append(rating_header.split('  '))\n",
    "        rating = span.findAll('table',attrs={'class':'review-ratings'})\n",
    "        rating = (recupTexteEntreBalise(str(rating),','))\n",
    "        note2.append(str(str(rating).replace('\\\\n','').replace('\\\\','')).split('  '))\n",
    "    Rating = []\n",
    "    for elem in note2:\n",
    "        if len(elem) != 0:\n",
    "            Rating.append(elem)\n",
    "    pagination_total = soup.findAll('div',attrs={'class':'pagination-total'})\n",
    "    pagination_total = str(pagination_total[0])\n",
    "    nb_com = pagination_total[41:len(pagination_total)-14]\n",
    "    return note, title, desc , title_column, Rating , nb_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserNot(soup):\n",
    "    liste = notation(soup)[4]\n",
    "    noteUser = []\n",
    "    value = []\n",
    "    liste1 = [' 1','2','3','4','5']\n",
    "    for z in range(0,len(liste)):\n",
    "        dico = {}\n",
    "        del liste[z][0]\n",
    "        for i in range(0,len(liste[z])-2):\n",
    "            if len(str(liste[z][i]).replace(' ',''))>1:\n",
    "                if len(str(liste[z][i+1]).replace(' ',''))>1: \n",
    "                    if liste[z][i] not in value:\n",
    "                        dico[liste[z][i]]=liste[z][i+1]\n",
    "                        value.append(liste[z][i+1])\n",
    "                else:\n",
    "                    j=i\n",
    "                    while str(liste[z][j+1]) in liste1:\n",
    "                        dico[liste[z][i]]=liste[z][j+1]\n",
    "                        j=j+1\n",
    "        noteUser.append(dico)\n",
    "\n",
    "    y=0\n",
    "    p = notation(soup)[0]\n",
    "    for k in noteUser:    \n",
    "        value = []\n",
    "        t=0\n",
    "        for cle,valeur in k.items():\n",
    "            if valeur=='5':\n",
    "                noteUser[y][cle] = p[y][t]\n",
    "                t=t+1\n",
    "        y=y+1\n",
    "    return noteUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
