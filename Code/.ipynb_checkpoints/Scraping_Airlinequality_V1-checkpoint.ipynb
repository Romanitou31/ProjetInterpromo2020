{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good = Date_Flown, Cleanliness, Food_And_Beverages, Wifi_And_Connectivity, Cabin_Staff_Service,Recommended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad = Queuing Times,Terminal Seating, Terminal Signs, Airport shopping,Experience At Airport,Type Of Traveller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recupTexteEntreBalise(texte, separateur):\n",
    "    \n",
    "    texte2 = []\n",
    "    lisI = []\n",
    "    lisS = []\n",
    "    \n",
    "    for i in range(0,len(texte)):\n",
    "        if str(texte[i]) == \"<\":\n",
    "            lisI.append(i)\n",
    "        if texte[i] == '>':\n",
    "            lisS.append(i)   \n",
    "\n",
    "    taille = len(lisI)\n",
    "    for h in range(0,taille):\n",
    "        if h < (taille-1):\n",
    "            texte2.append(texte[lisS[h]:lisI[h+1]])\n",
    "    \n",
    "    if separateur != 'non':\n",
    "        description = str(texte2).replace('>','').replace(',','').replace('\\'','').replace('，','')\n",
    "        description = description.split(separateur)\n",
    "    else:\n",
    "        description = texte2\n",
    "    \n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corp(listURL):\n",
    "    \n",
    "    nom_col = ['Airline_Name','Airline_Type','Region_Operation','Aircraft_Type','Cabin_Class','Type_Of_Lounge',\n",
    "                   'Type_Of_Traveller','Date_Visit','Date_Flown','Airport','Route','Category','Category_Detail',\n",
    "                   'Cabin_Staff_Service','Lounge_Staff_Service','Bar_And_Beverages','Food_And_Beverages','Ground_Service','Catering','Cleanliness',\n",
    "                  'Lounge_Comfort','Aisle_Space','Wifi_And_Connectivity','Inflight_Entertainment','Viewing_Tv_Screen','Power_Supply',\n",
    "                  'Seat','Seat_type','Seat_Comfort','Seat_Legroom','Seat_Storage','Seat_Width','Seat_Recline','Washrooms',\n",
    "                   'Value_For_Money','Overall_Customer_Rating','Overall_Service_Rating','Overall_Airline_Rating',\n",
    "                  'Recommended','Departure_city','Arrival_city','Nb_bus_taken','Nb_train_taken',\n",
    "                   'Nb_car_taken','Nb_plane_taken','Duration','Price_min','Price_max','Nb_sharing','Awards','Registration','Language']\n",
    "    \n",
    "    dataAirline = pd.DataFrame(columns = nom_col)\n",
    "    \n",
    "    for URL in listURL:\n",
    "        r = requests.get(URL)\n",
    "        page = r.text\n",
    "        soup = bs(page,'html.parser')\n",
    "        Nb_com = Nb_comments(soup)\n",
    "        \n",
    "        for j in range (1,int(Nb_com)//10+2):\n",
    "            r = requests.get(URL+'page/'+str(j)+'/')\n",
    "            page = r.text\n",
    "            soup = bs(page,'html.parser')\n",
    "            title = titre(soup)\n",
    "            desc = description(soup)\n",
    "            note = UserNot(soup)\n",
    "\n",
    "            airport=[]\n",
    "            for i in range(0,len(desc)):\n",
    "                airport.append(URL[47:])\n",
    "\n",
    "            df = pd.DataFrame(data=[title, desc, note, airport])\n",
    "            df=df.transpose()\n",
    "\n",
    "            Title = df[0]\n",
    "            Review = df[1]\n",
    "            Date_Visit, Terminal_Cleanliness, Food_Beverages, Wifi_Connectivity, Airport_Staff, Recommended = dic_col(df[2])\n",
    "            Airport = df[3]\n",
    "            # o.columns = ['Title', 'Review', 'Date_Flown', 'Cleanliness', 'Food_And_Beverages', 'Wifi_And_Connectivity', 'Cabin_Staff_Service','Recommended', 'Airport']\n",
    "            o = pd.DataFrame({'Date_Flown': Date_Visit, 'Cleanliness': Terminal_Cleanliness, 'Food_And_Beverages': Food_Beverages,\n",
    "                              'Wifi_And_Connectivity' : Wifi_Connectivity, 'Cabin_Staff_Service': Airport_Staff,\n",
    "                             'Recommended':Recommended, 'Title': Title, 'Review': Review, 'Airport': Airport })\n",
    "\n",
    "            dataAirline = pd.concat([dataAirline, o])\n",
    "\n",
    "\n",
    "    return dataAirline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of 175\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-cac2cf49875f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlistURL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.airlinequality.com/airport-reviews/berlin-schonefeld-airport/page/14/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#listURL.append('https://www.airlinequality.com/airport-reviews/rome-ciampino-airport/')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdataAirline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataAirline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataAirline.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-101-c52730c534a2>\u001b[0m in \u001b[0;36mcorp\u001b[1;34m(listURL)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitre\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mnote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUserNot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mairport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-100-a237fae50715>\u001b[0m in \u001b[0;36mUserNot\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvaleur\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvaleur\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mnoteUser\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "listURL=[]\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/singapore-changi-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/paris-cdg-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/new-york-jfk-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/london-city-airport/')\n",
    "#listURL.append('https://www.airlinequality.com/airport-reviews/berlin-schonefeld-airport/')\n",
    "listURL.append('https://www.airlinequality.com/airport-reviews/rome-ciampino-airport/')\n",
    "dataAirline = corp(listURL)\n",
    "c = dataAirline.to_json(orient='records')\n",
    "with open('dataAirline.json', 'a', encoding='utf8') as outfile:\n",
    "        json.dump(c, outfile, ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_col(o):\n",
    "# Prend en paramètre la colonne du DF contenant le dictionnaire des notes\n",
    "    Date_Visit = []\n",
    "    Terminal_Cleanliness = [] \n",
    "    Food_Beverages = [] \n",
    "    Wifi_Connectivity = []\n",
    "    Airport_Staff = []\n",
    "    Recommended = []\n",
    "\n",
    "    for i in range(0,len(o)):\n",
    "        if 'Date Visit' in (o[i]).keys():\n",
    "            Date_Visit.append((o[i]['Date Visit']))\n",
    "        else:\n",
    "            Date_Visit.append(' ')\n",
    "\n",
    "        if ' Terminal Cleanliness' in (o[i]).keys():\n",
    "            Terminal_Cleanliness.append((o[i][' Terminal Cleanliness']))\n",
    "        else:\n",
    "            Terminal_Cleanliness.append(' ')\n",
    "\n",
    "        if ' Food Beverages' in (o[i]).keys():\n",
    "            Food_Beverages.append((o[i][' Food Beverages']))\n",
    "        else:\n",
    "            Food_Beverages.append(' ')\n",
    "\n",
    "        if ' Wifi Connectivity' in (o[i]).keys():\n",
    "            Wifi_Connectivity.append((o[i][' Wifi Connectivity']))\n",
    "        else:\n",
    "            Wifi_Connectivity.append(' ')\n",
    "\n",
    "        if ' Airport Staff' in (o[i]).keys():\n",
    "            Airport_Staff.append((o[i][' Airport Staff']))\n",
    "        else:\n",
    "            Airport_Staff.append(' ')\n",
    "\n",
    "        if ' Recommended' in (o[i]).keys():\n",
    "            Recommended.append((o[i][' Recommended']))\n",
    "        else:\n",
    "            Recommended.append(' ')\n",
    "    return  Date_Visit, Terminal_Cleanliness, Food_Beverages, Wifi_Connectivity, Airport_Staff, Recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notation(soup):\n",
    "    note = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':'review'}):\n",
    "        toto = span.findAll('span',attrs={'class':'star fill'})\n",
    "        top = re.findall(r'[0-9]',str(toto))\n",
    "        if len(top)>0:\n",
    "            noteUser = []\n",
    "            taille = len(top)\n",
    "            for i in range(0,taille-1):\n",
    "                if top[i] >= top[i+1]:\n",
    "                    noteUser.append(top[i])\n",
    "            noteUser.append(top[taille-1])\n",
    "            note.append(noteUser)\n",
    "    return note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titre(soup):\n",
    "    title = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':'review'}):\n",
    "        top = span.findAll('h2',attrs={'class':'text_header'})\n",
    "        top = recupTexteEntreBalise(str(top),'non')\n",
    "        title.append(top[0][1:len(top[0])])\n",
    "        \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(soup):\n",
    "    desc = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':'review'}):\n",
    "        top = span.findAll('div',attrs={'class':'text_content'})\n",
    "        desc.append(recupTexteEntreBalise(str(top),','))\n",
    "        \n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_column_note(soup):\n",
    "    title_column = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':\"review\"}):\n",
    "        toto = span.findAll('td',attrs={'class':\"review-rating-header\"})\n",
    "        toto = recupTexteEntreBalise(str(toto),',')\n",
    "        toto = toto[0][1:len(toto[0])-1]\n",
    "        title_column.append(toto.split('  '))\n",
    "    return(title_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notation2(soup):\n",
    "    note = []\n",
    "    for span in soup.findAll('article',attrs={'itemprop':'review'}):\n",
    "        toto = span.findAll('table',attrs={'class':'review-ratings'})\n",
    "        toto = (recupTexteEntreBalise(str(toto),','))\n",
    "        note.append(str(str(toto).replace('\\\\n','').replace('\\\\','')).split('  '))\n",
    "    \n",
    "    Rating = []\n",
    "    for elem in note:\n",
    "        if len(elem) != 0:\n",
    "            Rating.append(elem)\n",
    "\n",
    "    return Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserNot(soup):\n",
    "    liste = notation2(soup)\n",
    "    noteUser = []\n",
    "    value = []\n",
    "    liste1 = [' 1','2','3','4','5']\n",
    "    for z in range(0,len(liste)):\n",
    "        dico = {}\n",
    "        del liste[z][0]\n",
    "        for i in range(0,len(liste[z])-2):\n",
    "            if len(str(liste[z][i]).replace(' ',''))>1:\n",
    "                if len(str(liste[z][i+1]).replace(' ',''))>1: \n",
    "                    if liste[z][i] not in value:\n",
    "                        dico[liste[z][i]]=liste[z][i+1]\n",
    "                        value.append(liste[z][i+1])\n",
    "                else:\n",
    "                    j=i\n",
    "                    while str(liste[z][j+1]) in liste1:\n",
    "                        dico[liste[z][i]]=liste[z][j+1]\n",
    "                        j=j+1\n",
    "        noteUser.append(dico)\n",
    "\n",
    "    y=0\n",
    "    p = notation(soup)\n",
    "    for k in noteUser:    \n",
    "        value = []\n",
    "        t=0\n",
    "        for cle,valeur in k.items():\n",
    "            if valeur=='5':\n",
    "                noteUser[y][cle] = p[y][t]\n",
    "                t=t+1\n",
    "        y=y+1\n",
    "    return noteUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nb_comments(soup):\n",
    "    toto = soup.findAll('div',attrs={'class':'pagination-total'})\n",
    "    toto = str(toto[0])\n",
    "    nb_com = toto[41:len(toto)-14]\n",
    "    return(nb_com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
